import os
import base64
import time
import asyncio
import aiohttp
import tempfile
import logging
from enum import Enum
from typing import Optional
from pathlib import Path
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.types import Message, CallbackQuery
from aiogram.filters import Command
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.utils.keyboard import InlineKeyboardBuilder

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö –Ω–∞–ª–∏—á–∏–µ
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–æ–∫–µ–Ω–æ–≤
if not TELEGRAM_TOKEN:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç TELEGRAM_TOKEN –≤ —Ñ–∞–π–ª–µ .env")
if not OPENAI_API_KEY:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç OPENAI_API_KEY –≤ —Ñ–∞–π–ª–µ .env")
if not GEMINI_API_KEY:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç GEMINI_API_KEY –≤ —Ñ–∞–π–ª–µ .env")

# –û—á–∏—Å—Ç–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
OPENAI_API_KEY = OPENAI_API_KEY.strip() if OPENAI_API_KEY else None
TELEGRAM_TOKEN = TELEGRAM_TOKEN.strip() if TELEGRAM_TOKEN else None
GEMINI_API_KEY = GEMINI_API_KEY.strip() if GEMINI_API_KEY else None

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
OPENAI_IMAGE_EDIT_URL = "https://api.openai.com/v1/images/generations"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º generations –≤–º–µ—Å—Ç–æ edits
GOOGLE_VISION_URL = "https://vision.googleapis.com/v1/images:annotate"
OPENAI_MODEL = "dall-e-2"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º DALL-E 2 –º–æ–¥–µ–ª—å
MAX_IMAGE_SIZE = 4 * 1024 * 1024  # 4MB
MAX_RETRIES = 3
CONCURRENT_REQUESTS_LIMIT = 10

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ AI —Å–µ—Ä–≤–∏—Å–æ–≤
class AIService(str, Enum):
    OPENAI = "openai"
    GOOGLE = "google"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ FSM
bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher(storage=MemoryStorage())
semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS_LIMIT)

# –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ñ–∞–π–ª–æ–≤
TEMP_DIR = Path(tempfile.gettempdir()) / "ktc_photo_bot"
TEMP_DIR.mkdir(parents=True, exist_ok=True)


# --- FSM (–º–∞—à–∏–Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π) ---
class EditStates(StatesGroup):
    choosing_service = State()
    waiting_for_prompt = State()
    waiting_for_result = State()

# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –≤—ã–±–æ—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞
def get_service_keyboard():
    builder = InlineKeyboardBuilder()
    builder.button(text="OpenAI", callback_data=f"service:{AIService.OPENAI}")
    builder.button(text="Google AI", callback_data=f"service:{AIService.GOOGLE}")
    builder.adjust(2)
    return builder.as_markup()


# --- –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ---
async def call_google_vision(image_path: str, prompt: str) -> Optional[str]:
    try:
        import cv2
        import numpy as np
        from PIL import Image, ImageEnhance, ImageFilter
    except ImportError:
        raise ImportError("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: pip install opencv-python pillow")

    headers = {"Authorization": f"Bearer {GEMINI_API_KEY}"}
    output_path = str(Path(image_path).with_suffix('.edited.png'))

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if Path(image_path).stat().st_size > MAX_IMAGE_SIZE:
        raise ValueError(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–∞–µ—Ç {MAX_IMAGE_SIZE // 1024 // 1024}MB")

    async with semaphore:
        for attempt in range(MAX_RETRIES):
            try:
                async with aiohttp.ClientSession() as session:
                    # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
                    with open(image_path, 'rb') as img_file:
                        img_content = base64.b64encode(img_file.read()).decode('utf-8')

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ Google Vision API
                    request_data = {
                        "requests": [
                            {
                                "image": {"content": img_content},
                                "features": [
                                    {"type": "IMAGE_PROPERTIES"},
                                    {"type": "LABEL_DETECTION"},
                                    {"type": "FACE_DETECTION"},
                                    {"type": "OBJECT_LOCALIZATION"}
                                ]
                            }
                        ]
                    }

                    async with session.post(
                        GOOGLE_VISION_URL,
                        headers=headers,
                        json=request_data,
                        timeout=aiohttp.ClientTimeout(total=180)
                    ) as resp:
                        resp.raise_for_status()
                        response_data = await resp.json()

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
                        response = response_data['responses'][0]
                        
                        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                        image = Image.open(image_path)
                        
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω—É–∂–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
                        prompt_lower = prompt.lower()
                        
                        if '—è—Ä–∫–æ—Å—Ç—å' in prompt_lower or '—Å–≤–µ—Ç–ª–µ–µ' in prompt_lower:
                            enhancer = ImageEnhance.Brightness(image)
                            image = enhancer.enhance(1.5)
                            
                        if '–∫–æ–Ω—Ç—Ä–∞—Å—Ç' in prompt_lower:
                            enhancer = ImageEnhance.Contrast(image)
                            image = enhancer.enhance(1.3)
                            
                        if '–Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å' in prompt_lower or '—Ü–≤–µ—Ç–∞' in prompt_lower:
                            enhancer = ImageEnhance.Color(image)
                            image = enhancer.enhance(1.4)
                            
                        if '—Ä–µ–∑–∫–æ—Å—Ç—å' in prompt_lower or '—á–µ—Ç–∫–æ—Å—Ç—å' in prompt_lower:
                            enhancer = ImageEnhance.Sharpness(image)
                            image = enhancer.enhance(1.5)
                            
                        if '—Ä–∞–∑–º—ã—Ç–∏–µ' in prompt_lower or '–±–ª—é—Ä' in prompt_lower:
                            image = image.filter(ImageFilter.GaussianBlur(radius=2))

                        # –ï—Å–ª–∏ –µ—Å—Ç—å –ª–∏—Ü–∞ –Ω–∞ —Ñ–æ—Ç–æ –∏ –∑–∞–ø—Ä–æ—à–µ–Ω–∞ –∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∞
                        if '–ª–∏—Ü–æ' in prompt_lower or '–ø–æ—Ä—Ç—Ä–µ—Ç' in prompt_lower:
                            if 'faceAnnotations' in response:
                                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ cv2 –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Ü
                                cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
                                
                                for face in response['faceAnnotations']:
                                    vertices = face['fdBoundingPoly']['vertices']
                                    x1 = vertices[0]['x']
                                    y1 = vertices[0]['y']
                                    x2 = vertices[2]['x']
                                    y2 = vertices[2]['y']
                                    
                                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∫ –æ–±–ª–∞—Å—Ç–∏ –ª–∏—Ü–∞
                                    face_roi = cv_image[y1:y2, x1:x2]
                                    if face_roi.size > 0:
                                        # –£–ª—É—á—à–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –ª–∏—Ü–∞
                                        lab = cv2.cvtColor(face_roi, cv2.COLOR_BGR2LAB)
                                        l, a, b = cv2.split(lab)
                                        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                                        cl = clahe.apply(l)
                                        limg = cv2.merge((cl,a,b))
                                        face_roi = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
                                        cv_image[y1:y2, x1:x2] = face_roi
                                
                                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ PIL
                                image = Image.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))

                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–∏–Ω–∞–Ω—Ç–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤
                        if '—Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è' in prompt_lower:
                            if 'imagePropertiesAnnotation' in response:
                                colors = response['imagePropertiesAnnotation']['dominantColors']['colors']
                                # –°–æ–∑–¥–∞–µ–º LUT –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–∏–Ω–∞–Ω—Ç–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤
                                cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
                                for color in colors[:3]:  # –ë–µ—Ä–µ–º —Ç—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ü–≤–µ—Ç–∞
                                    rgb = [
                                        int(color['color']['red']),
                                        int(color['color']['green']),
                                        int(color['color']['blue'])
                                    ]
                                    # –£—Å–∏–ª–∏–≤–∞–µ–º –¥–æ–º–∏–Ω–∞–Ω—Ç–Ω—ã–µ —Ü–≤–µ—Ç–∞
                                    mask = cv2.inRange(
                                        cv_image,
                                        np.array([max(0, c - 30) for c in rgb]),
                                        np.array([min(255, c + 30) for c in rgb])
                                    )
                                    cv_image[mask > 0] = [min(255, c * 1.2) for c in rgb]
                                image = Image.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                        image.save(output_path, 'PNG', quality=95)
                        logger.info(f"Google Vision API —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                        return output_path

            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                if attempt == MAX_RETRIES - 1:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫: {e}")
                    raise
                await asyncio.sleep(2 ** attempt)

            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                raise

async def call_openai_image_edit(image_path: str, prompt: str, size="1024x1024") -> Optional[str]:
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ OPENAI_API_KEY –≤ —Ñ–∞–π–ª–µ .env")
        
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY.strip()}",
        "Content-Type": "application/json"
    }
    output_path = str(Path(image_path).with_suffix('.edited.png'))

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if Path(image_path).stat().st_size > MAX_IMAGE_SIZE:
        raise ValueError(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–µ–≤—ã—à–∞–µ—Ç {MAX_IMAGE_SIZE // 1024 // 1024}MB")

    async with semaphore:
        for attempt in range(MAX_RETRIES):
            try:
                async with aiohttp.ClientSession() as session:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ OpenAI
                    data = aiohttp.FormData()
                    data.add_field('model', OPENAI_MODEL)
                    data.add_field('prompt', prompt)
                    data.add_field('size', size)
                    data.add_field('n', '1')
                    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
                    with open(image_path, 'rb') as img:
                        data.add_field('image', img, filename='image.png', content_type='image/png')

                    async with session.post(
                        OPENAI_IMAGE_EDIT_URL,
                        headers=headers,
                        data=data,
                        timeout=aiohttp.ClientTimeout(total=180)
                    ) as resp:
                        resp.raise_for_status()
                        response_data = await resp.json()

                    item = response_data["data"][0]

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if "b64_json" in item:
                        image_bytes = base64.b64decode(item["b64_json"])
                        await asyncio.to_thread(
                            lambda: Path(output_path).write_bytes(image_bytes)
                        )
                    elif "url" in item:
                        async with session.get(
                            item["url"],
                            timeout=aiohttp.ClientTimeout(total=60)
                        ) as img_resp:
                            img_resp.raise_for_status()
                            content = await img_resp.read()
                            await asyncio.to_thread(
                                lambda: Path(output_path).write_bytes(content)
                            )
                    else:
                        raise ValueError("Unexpected response from OpenAI")

                    logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {output_path}")
                    return output_path
            
            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                if attempt == MAX_RETRIES - 1:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫: {e}")
                    raise
                await asyncio.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                raise


# –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
async def cleanup_old_files(max_age_hours: int = 24):
    """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞"""
    try:
        current_time = time.time()
        for file in TEMP_DIR.glob("tmp_*"):
            if current_time - file.stat().st_mtime > max_age_hours * 3600:
                file.unlink()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")


# --- –ö–æ–º–∞–Ω–¥–∞ /start ---
@dp.message(Command("start"))
async def cmd_start(message: Message):
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ, –∏ —è –ø–æ–º–æ–≥—É —Ç–µ–±–µ –∏–∑–º–µ–Ω–∏—Ç—å –µ–≥–æ.\n"
        "ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã: OpenAI –∏ Google AI\n"
        "üì∏ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–æ—Ç–æ: 4MB"
    )
    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    await cleanup_old_files()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞
@dp.callback_query(lambda c: c.data.startswith("service:"))
async def process_service_choice(callback_query: CallbackQuery, state: FSMContext):
    service = callback_query.data.split(":")[1]
    await state.update_data(service=service)
    
    await callback_query.message.edit_text(
        "‚úèÔ∏è –ö–∞–∫ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ?",
        reply_markup=None
    )
    await state.set_state(EditStates.waiting_for_prompt)
    await callback_query.answer()


# --- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª —Ñ–æ—Ç–æ ---
@dp.message(F.photo)
async def handle_photo(message: Message, state: FSMContext):
    try:
        photo = message.photo[-1]
        file_info = await bot.get_file(photo.file_id)
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        input_path = TEMP_DIR / f"tmp_{message.chat.id}_{message.message_id}.jpg"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if file_info.file_size and file_info.file_size > MAX_IMAGE_SIZE:
            await message.answer(
                f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_IMAGE_SIZE // 1024 // 1024}MB"
            )
            return

        await bot.download_file(file_info.file_path, str(input_path))
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {input_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ —Ñ–æ—Ç–æ –≤ FSM
        await state.update_data(image_path=str(input_path))
        
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å —Å–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        await message.answer(
            "ü§ñ –í—ã–±–µ—Ä–∏—Ç–µ —Å–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
            reply_markup=get_service_keyboard()
        )
        await state.set_state(EditStates.choosing_service)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–æ—Ç–æ: {e}")
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–æ—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
        await state.clear()


# --- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –ø—Ä–æ–º–ø—Ç–æ–º ---
@dp.message(EditStates.waiting_for_prompt)
async def handle_prompt(message: Message, state: FSMContext):
    user_data = await state.get_data()
    image_path = user_data.get("image_path")
    service = user_data.get("service", AIService.OPENAI)
    
    if not image_path or not Path(image_path).exists():
        await message.answer("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∑–∞–Ω–æ–≤–æ.")
        await state.clear()
        return

    prompt = message.text.strip()
    if not prompt:
        await message.answer("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –∂–µ–ª–∞–µ–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è.")
        return

    await message.answer("ü™Ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ... —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.")
    await state.set_state(EditStates.waiting_for_result)

    try:
        # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–µ—Ä–≤–∏—Å–∞
        process_func = call_openai_image_edit if service == AIService.OPENAI else call_google_vision
        output_path = await process_func(image_path, prompt)
        
        if output_path and Path(output_path).exists():
            async with aiohttp.ClientSession() as session:
                with open(output_path, "rb") as f:
                    await message.answer_photo(f, caption=f"‚úÖ –ì–æ—Ç–æ–≤–æ! (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–µ—Ä–µ–∑ {service})")
        else:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

    except ValueError as ve:
        error_msg = str(ve)
        logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {error_msg}")
        await message.answer(f"‚ö†Ô∏è {error_msg}")
    except ImportError as ie:
        error_msg = str(ie)
        logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫: {error_msg}")
        await message.answer(f"‚ö†Ô∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {error_msg}")
    except Exception as e:
        error_msg = str(e)
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {error_msg}")
        await message.answer(f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {error_msg}")

    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        try:
            for file in [Path(image_path), Path(image_path + ".edited.png")]:
                if file.exists():
                    file.unlink()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
        await state.clear()


# --- –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ---
async def main():
    print("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω (aiogram 3.x, —Å –¥–∏–∞–ª–æ–≥–æ–º –¥–ª—è prompt)")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
